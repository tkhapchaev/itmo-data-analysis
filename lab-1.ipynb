{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Сбор данных с arXiv (250 публикаций)",
   "id": "5aeb0b772afe3704"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T17:10:55.588816Z",
     "start_time": "2025-02-26T17:10:53.447309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import feedparser\n",
    "\n",
    "def fetch_arxiv(query, max_results=250):\n",
    "    base_url = \"http://export.arxiv.org/api/query?\"\n",
    "    params = {\n",
    "        \"search_query\": f\"all:{query}\",\n",
    "        \"start\": 0,\n",
    "        \"max_results\": max_results,\n",
    "        \"sortBy\": \"submittedDate\",\n",
    "        \"sortOrder\": \"descending\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    feed = feedparser.parse(response.text)\n",
    "    publications = []\n",
    "\n",
    "    for entry in feed.entries:\n",
    "        pub = {\n",
    "            \"title\": entry.title.strip(),\n",
    "            \"authors\": [author.name for author in entry.authors],\n",
    "            \"summary\": entry.summary.strip()\n",
    "        }\n",
    "        publications.append(pub)\n",
    "\n",
    "    return publications\n",
    "\n",
    "query = \"machine learning\"\n",
    "publications = fetch_arxiv(query, max_results=250)\n",
    "print(f\"Получено {len(publications)} публикаций\")"
   ],
   "id": "8d9bfb0258710a66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Получено 250 публикаций\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Выделение ключевых слов для каждой публикации. Используем TF‑IDF, чтобы для каждой публикации (на основе объединённого заголовка и аннотации) выбрать топ‑N слов",
   "id": "3d86669e0c2277c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T18:04:20.735553Z",
     "start_time": "2025-02-24T18:04:20.263488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def extract_keywords_from_text(text, top_n=5):\n",
    "    text_clean = re.sub(r\"[^\\w\\s]\", \"\", text.lower())\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf_matrix = vectorizer.fit_transform([text_clean])\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    scores = tfidf_matrix.toarray()[0]\n",
    "\n",
    "    if len(scores) == 0:\n",
    "        return []\n",
    "\n",
    "    top_indices = np.argsort(scores)[-top_n:][::-1]\n",
    "    keywords = [feature_names[i] for i in top_indices]\n",
    "\n",
    "    return keywords\n",
    "\n",
    "def add_keywords_to_publications(publications, top_n=5):\n",
    "    for pub in publications:\n",
    "        combined_text = pub[\"title\"] + \". \" + pub[\"summary\"]\n",
    "        pub[\"keywords\"] = extract_keywords_from_text(combined_text, top_n=top_n)\n",
    "\n",
    "    return publications\n",
    "\n",
    "publications = add_keywords_to_publications(publications, top_n=5)\n",
    "\n",
    "for pub_i in range(10):\n",
    "    print(\"Ключевые слова первой публикации:\", publications[pub_i][\"keywords\"])"
   ],
   "id": "4b66ce581d566d5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ключевые слова первой публикации: ['distribution', 'using', 'generation', 'score', 'divergence']\n",
      "Ключевые слова первой публикации: ['skill', 'shift', 'oss', 'space', 'longhorizon']\n",
      "Ключевые слова первой публикации: ['visual', 'models', 'human', 'improve', 'cognition']\n",
      "Ключевые слова первой публикации: ['knowledge', 'leke', 'fleke', 'locatethenedit', 'editing']\n",
      "Ключевые слова первой публикации: ['theory', 'mind', 'autotom', 'bayesian', 'model']\n",
      "Ключевые слова первой публикации: ['driving', 'video', 'model', 'vavim', 'vavam']\n",
      "Ключевые слова первой публикации: ['design', 'curvature', 'target', 'surfaces', 'optimization']\n",
      "Ключевые слова первой публикации: ['text', 'ai', 'content', 'aigenerated', 'using']\n",
      "Ключевые слова первой публикации: ['set', 'learning', 'using', 'curriculum', 'curricula']\n",
      "Ключевые слова первой публикации: ['ai', 'risks', 'human', 'agents', 'current']\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Построение графа ключевых слов. Каждая публикация добавляет связь между всеми парами ключевых слов, встречающихся в ней",
   "id": "ecd808943579ce8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T18:04:26.467347Z",
     "start_time": "2025-02-24T18:04:26.451145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "\n",
    "def build_keywords_graph(publications):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for pub in publications:\n",
    "        keywords = pub.get(\"keywords\", [])\n",
    "\n",
    "        for kw in keywords:\n",
    "            if kw not in G:\n",
    "                G.add_node(kw)\n",
    "\n",
    "        for i in range(len(keywords)):\n",
    "            for j in range(i+1, len(keywords)):\n",
    "                kw1, kw2 = keywords[i], keywords[j]\n",
    "\n",
    "                if G.has_edge(kw1, kw2):\n",
    "                    G[kw1][kw2][\"weight\"] += 1\n",
    "                else:\n",
    "                    G.add_edge(kw1, kw2, weight=1)\n",
    "\n",
    "    return G\n",
    "\n",
    "G_kw = build_keywords_graph(publications)\n",
    "\n",
    "print(\"Узлов в графе ключевых слов:\", G_kw.number_of_nodes())\n",
    "print(\"Ребер в графе ключевых слов:\", G_kw.number_of_edges())"
   ],
   "id": "f7e0962d7cf22f6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Узлов в графе ключевых слов: 768\n",
      "Ребер в графе ключевых слов: 2423\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Кластеризация и оценка графа ключевых слов. Используем библиотеку louvain для выявления кластеров и вычисляем модулярность",
   "id": "c06b6cac379d3b4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T18:04:29.034422Z",
     "start_time": "2025-02-24T18:04:28.945444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import community.community_louvain as community_louvain\n",
    "\n",
    "partition = community_louvain.best_partition(G_kw, weight='weight')\n",
    "modularity = community_louvain.modularity(partition, G_kw, weight='weight')\n",
    "\n",
    "print(\"Модулярность кластеризации ключевых слов:\", modularity)\n",
    "\n",
    "clusters = {}\n",
    "\n",
    "for node, comm in partition.items():\n",
    "    clusters.setdefault(comm, []).append(node)\n",
    "\n",
    "for comm, nodes in clusters.items():\n",
    "    print(f\"Кластер {comm}: {nodes}\")"
   ],
   "id": "ebb471d426bbf6aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модулярность кластеризации ключевых слов: 0.66886464\n",
      "Кластер 15: ['distribution', 'score', 'divergence', 'design', 'curvature', 'target', 'surfaces', 'optimization', 'inverse', 'active', 'tandem', 'kernel', 'random', 'laplacian', 'features', 'approximate', 'nonlinear', 'bregmankaczmarz', 'block', 'method', 'averaging', 'best', 'problems', 'contract', 'chip', 'eda', 'edaq', 'sufficient', 'noneuclidean', 'statistical', 'menu', 'items', 'hand', 'pretraining', 'similar', 'search', 'routing', 'solution', 'solar', 'flares', 'source', 'shape', 'level', 'pde', 'cal', 'error', 'queries', 'log']\n",
      "Кластер 1: ['using', 'driving', 'vavim', 'vavam', 'set', 'learning', 'curriculum', 'curricula', 'rl', 'training', 'simulation', 'pipeline', 'stage', 'predictive', 'odes', 'simultaneous', 'ml', 'datadependent', 'bounds', 'prior', 'deep', 'sciml', 'machine', 'scientific', 'moma', 'material', 'modular', 'sheaf', 'applications', 'multihead', 'multitask', 'scenarios', 'times', 'hifikpi', 'taxonomy', 'financial', 'problemsolving', 'logic', 'image', 'stellar', 'medium', 'reinforcement', 'simbav2', 'potential', 'images', 'steganography', 'augmentation', 'datasets', 'medical', 'modality', 'sc', 'curricuvlm', 'autonomous', 'study', 'gigl', 'gnns', 'geospatial', 'geoaggregators', 'pgdat', 'decisionmaking', 'new', 'molecules', 'oscillator', 'generating', 'strength', 'word', 'words']\n",
      "Кластер 11: ['generation', 'text', 'winn', 'updates', 'inference', 'context', 'recommendation', 'graph', 'writing', 'writeragent', 'novel', 'character', 'hijacking', 'embedding', 'memory', 'embeddings', 'prediction', 'drugtarget', 'drugs', 'sample', 'bound', 'complexity', 'transition', 'devices', 'benchmark', 'dataset', 'specifications', 'specification', 'formal', 'scalefree', 'rademacher', 'complexities', 'variational', 'trees', 'ultrametric', 'gnn', 'gnnvault', 'link', 'directed', 'undirected', 'ocr', 'arabic', 'document']\n",
      "Кластер 10: ['skill', 'shift', 'oss', 'space', 'longhorizon', 'balancing', 'load', 'algorithm', 'expert', 'integer', 'realworld', 'covariate', 'equation', 'holder', 'function', 'scheme', 'opf', 'local', 'power']\n",
      "Кластер 3: ['visual', 'models', 'human', 'improve', 'cognition', 'content', 'crosslingual', 'alignment', 'mllms', 'language', 'tasks', 'reasoning', 'o3mini', 'accuracy', 'longer', 'pruning', 'pp', 'probing', 'states', 'llms', 'english', 'multilingual', 'representation', 'tokens', 'lightthinker', 'potentials', 'transfer', 'vlm', 'benchmarks', 'domainspecific', 'domains', 'representations', 'edge', 'discovery', 'languages', 'mstyledistance', 'distractors', 'rag', 'correct', 'genome', 'sampling', 'cka', 'unlearning', 'unlearn', 'sensitive', 'lume', 'align', 'points', 'hallucination', 'correction', 'range', 'wide', 'obliviate', 'copyright', 'questions', 'questionasking', 'ask', 'speculative', 'draft', 'taskspecific', 'vqa', 'question', 'sensemaking']\n",
      "Кластер 5: ['knowledge', 'leke', 'fleke', 'locatethenedit', 'editing', 'theory', 'mind', 'autotom', 'bayesian', 'model', 'spectral', 'effective', 'dynamics', 'information', 'asd', 'rois', 'fmri', 'penalties', 'ell_0', 'signal', 'privacy', 'attacks', 'framework', 'nids', 'communications', 'reconstructionoriented', 'existing', 'spd', 'pass', 'jailbreaking', 'defences', 'jailbreak', 'available', 'systematic', 'multiagent', 'supervised', 'vmmr', 'attention', 'proposed', 'mechanisms', 'attentionengine', 'hardware', 'agent', 'shared', 'limited', 'gcg', 'energy', 'module', 'feature', 'objectives', 'aggregation', 'preference', 'rlhf', 'extractors', 'propagation', 'promptspecific', 'prompts', 'leaderboards', 'specificity', 'failure', 'api', 'planning']\n",
      "Кластер 8: ['video', 'ai', 'aigenerated', 'risks', 'agents', 'current', 'paradigms', 'evaluation', 'research', 'recent', 'detection', 'sif', 'strategies', 'corpus', 'responses', 'commands', 'cybersecurity', 'semiautonomous', 'hierarchical', 'tag', 'systems', 'levels', 'education', 'assessments', 'students', 'tracking', 'ocean', 'metric', 'automatic', 'propose', 'conditioned', 'concentration', 'eeg', 'intent', 'interfaces', 'traditional', 'lvlms', 'tools', 'threat', 'cybersentinel', 'emergent', 'sources', 'symmetric', 'symmetries', 'physical', 'historical', 'cultural', 'timetravel', 'concepts', 'dynamic', 'personalizing', 'voronoi', 'construction', 'distributed', 'madvoro']\n",
      "Кластер 18: ['parameters', 'data', 'collapse', 'machinegenerated', 'digitized', 'time', 'ds20k', 'acquisition', 'foundation', 'series', 'mantis', 'person', 'identification', 'variability', 'vibration', 'synthetic', 'samples', 'scaling', 'fewer', 'stability', 'analysis', 'salsarl', 'actions', 'scarcity', 'metadata', 'sentiment', 'router', 'clusters', 'moe', 'weights', 'input', 'phase', 'psf', 'aberration', 'ultrasound', 'estimation', 'functional', 'anova', 'seizure', 'freedom', 'epilepsy', 'pressure', 'verification', 'provenance', 'supply', 'selection', 'style', 'gain', 'nonnegative', 'factorization', 'manifoldvalued', 'open', 'vvvx', 'cluster', 'variation', 'registration', 'behavior', 'players', 'species', 'small', 'estimator', 'methodology', 'cv', 'fetal', 'fetalclip']\n",
      "Кластер 13: ['uncertainty', 'ood', 'entropy', 'transformers', 'speed', 'sequence', 'train', 'learningbased', 'approach', 'variables', 'mpc', 'spatiotemporal', 'stev', 'expanding', 'mtsf', 'rewardfree', 'vehicle', 'control', 'state', 'ionospheric', 'trained', 'samplingbased', 'horizon', 'safety', 'topics', 'motion', 'humanoidvla', 'universal']\n",
      "Кластер 16: ['leap', 'drug', 'gene', 'perturbation', 'neural', 'linear', 'resource', 'networks', 'ilp', 'milp', 'programming', 'structure', 'weight', 'occupancy', 'correlation', 'baseline', 'gauge', 'equivariant', 'topological', 'symmetry', 'forecasting', 'predictors', 'ssrf', 'screening', 'occprophet', 'computational', 'refiner', 'calibration', 'w_star', 'true', 'provably', 'latent', 'vanishing', 'manifold']\n",
      "Кластер 2: ['extraction', 'french', 'transformer', 'relations', 'results', 'ndt', 'semisupervised', 'pseudodata', 'network', 'uav', 'mlbased', 'multimodal', 'm2lads', 'dashboards', 'large', 'emlms', 'future', 'positional', 'external', 'sequential', 'riemannian', 'sparse', 'learn', 'matrix', 'zeroshot', 'movement', 'pedestrian', 'realtime', 'identify', 'losa', 'lora', 'lowrank']\n",
      "Кластер 23: ['policy', 'gripper', 'retraining', 'grippers', 'diffusion', 'infringement', 'noninfringing', 'mitigation', 'noise', 'illumination', 'lowlight', 'enhancement', 'process', 'ct']\n",
      "Кластер 12: ['mamba', 'understanding', 'ssms', 'tokentotoken', 'social', 'reward', 'imaging', 'lfm', '3d', 'reconstruction', 'intensity', 'welfare', 'fairness', 'regret', 'vlms', 'similarity', 'pairbench', 'metrics', 'evaluators', 'decision', 'humanai', 'capability', 'capabilities', 'architecture', 'transmamba', 'crossover', 'object', 'scene', 'thompson', 'online']\n",
      "Кластер 0: ['peptide', 'protein', 'ptm', 'pretrained', 'classification', 'audio', 'kad', 'efficient', 'fad', 'evaluating', 'cpp', 'wavelet', 'lfp', 'nac', 'classes', 'openset', 'wild', 'neuromorphic', 'survey', 'processing']\n",
      "Кластер 4: ['robustness', 'explanations', 'llm', 'steering', 'semantic', 'behaviors', 'adversarial', 'activation', 'proving', 'use', 'decoding', 'punctured', 'code', 'codes', 'rates', 'units', 'kernels', 'pim', 'finetuning', 'federated', 'performance', 'fedsb', 'communication', 'segmentation', 'tumor', 'test', 'nf', 'mask', 'quality', 'explanation', 'qge', 'ad', 'diagnosis', 'clinical', 'including', 'objects', 'tuning', 'hyperparameter', 'urban', 'urbansam', 'ssss', 'pseudolabels', 'cardiac', 'modules', 'advertisement', 'youtube', 'dnn', 'macpruning', 'em', 'eigenshield', 'causal', 'lserve', 'kv', 'pr', 'systemlevel', 'comprehensive', 'autoencoders', 'compound']\n",
      "Кластер 27: ['bowel', 'bs', 'patterns', 'sound', 'examples', 'cloud', 'orca', 'recognition', 'offloading', 'speech', 'retrievalaugmented', 'induction', 'schema', 'schemex', 'timedistill', 'mlp', 'kd']\n",
      "Кластер 19: ['compression', 'cache', 'quantization', 'key', 'svdq', 'singular', 'importance', 'scores', 'spectrum', 'value', 'matrices', 'values']\n",
      "Кластер 6: ['number', 'cop', 'cops', 'graphs', 'weak', 'expansion', 'nodes', 'hypergraphs', 'hypergraph', 'methods', 'molecular', 'crystals', 'accurate', 'quantum', 'modeling', 'problem', 'regression', 'risk', 'dimensionfree', 'algorithms', 'classical', 'regressor', 'lie', 'mathfraksun', 'trace', 'circuits', 'circuit', 'measures', 'cart', 'misclassification', 'mdfs', 'branched', 'differentiable', 'bdlo', 'dlos', 'polynomialtime', 'conjecture', 'lowdegree', 'recovery', 'ruleset', 'submissions', 'algoperf', 'spatial', 'soil', 'emissions', 'land']\n",
      "Кластер 7: ['parties', 'political', 'wahlomat', 'vaa', 'rightwing']\n",
      "Кластер 9: ['update', 'internal', 'rule', 'predictions', 'jeffreys']\n",
      "Кластер 14: ['virtual', 'reality', 'learners', 'annotations', 'educators']\n",
      "Кластер 17: ['users', 'preferences', 'profiles', 'torque', 'hip', 'music', 'composeon', 'musical']\n",
      "Кластер 20: ['leq', 'template', 'bank', 'mass', 'templategenn']\n",
      "Кластер 21: ['bugcerberus', 'fixing', 'issue', 'bug', 'localization']\n",
      "Кластер 22: ['counting', 'outdoor', 'seeds', 'soybean', 'fields']\n",
      "Кластер 24: ['coticl', 'cot', 'lab', 'incontext', 'token', 'conversational', 'rewriting']\n",
      "Кластер 25: ['demand', 'shocks', 'prices', 'pricing', 'qlearning']\n",
      "Кластер 26: ['terrains', 'perception', 'policies', 'humanoid', 'robots']\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. Анализ центральностей ключевых слов. Вычислим несколько мер центральности",
   "id": "a80e46a13f0d0536"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T18:04:41.496191Z",
     "start_time": "2025-02-24T18:04:38.584201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "degree_centrality = nx.degree_centrality(G_kw)\n",
    "betweenness_centrality = nx.betweenness_centrality(G_kw, weight='weight')\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G_kw, max_iter=1000, weight='weight')\n",
    "closeness_centrality = nx.closeness_centrality(G_kw)\n",
    "\n",
    "top_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"Топ-5 по degree centrality:\", top_degree)\n",
    "\n",
    "top_degree = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"Топ-5 по betweenness centrality:\", top_degree)\n",
    "\n",
    "top_degree = sorted(eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"Топ-5 по eigenvector centrality:\", top_degree)\n",
    "\n",
    "top_degree = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"Топ-5 по closeness centrality:\", top_degree)"
   ],
   "id": "c4684631e57269a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-5 по degree centrality: [('models', 0.15514993481095177), ('learning', 0.14863102998696218), ('model', 0.10039113428943937), ('data', 0.09778357235984354), ('llms', 0.06779661016949153)]\n",
      "Топ-5 по betweenness centrality: [('learning', 0.2108364355015911), ('models', 0.18211161006425639), ('data', 0.13687021774542948), ('model', 0.10996175397076602), ('llms', 0.0754224193421871)]\n",
      "Топ-5 по eigenvector centrality: [('models', 0.4275209451599416), ('learning', 0.38999307172073433), ('model', 0.3361483654063575), ('data', 0.22105962432174103), ('language', 0.176920679688001)]\n",
      "Топ-5 по closeness centrality: [('learning', 0.4219755355441988), ('models', 0.4166179259635288), ('data', 0.4010978169637234), ('model', 0.4006314241533004), ('training', 0.3677086710478531)]\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "6. Построение графа публикаций. В графе публикаций узлы — это публикации, а ребро между двумя публикациями имеет вес, равный количеству общих ключевых слов",
   "id": "12b98aeb1524eba9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T18:04:47.919419Z",
     "start_time": "2025-02-24T18:04:47.886515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_publications_graph(publications):\n",
    "    G_pub = nx.Graph()\n",
    "    n = len(publications)\n",
    "\n",
    "    for i, pub in enumerate(publications):\n",
    "        G_pub.add_node(i, title=pub[\"title\"], keywords=pub[\"keywords\"])\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            common = set(publications[i][\"keywords\"]).intersection(publications[j][\"keywords\"])\n",
    "            if common:\n",
    "                G_pub.add_edge(i, j, weight=len(common))\n",
    "\n",
    "    return G_pub\n",
    "\n",
    "G_pub = build_publications_graph(publications)\n",
    "print(\"Узлов (публикаций) в графе:\", G_pub.number_of_nodes())\n",
    "print(\"Ребер (связей) в графе публикаций:\", G_pub.number_of_edges())"
   ],
   "id": "2a4b48476306e5cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Узлов (публикаций) в графе: 250\n",
      "Ребер (связей) в графе публикаций: 2391\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "7. Поиск наиболее близких публикаций по графу. Реализуем функцию, которая по заданному индексу публикации находит её соседей, отсортированных по весу ребра",
   "id": "d8491e52f2b9abf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T18:24:13.276907Z",
     "start_time": "2025-02-24T18:24:13.267790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_similar_publications(G_pub, pub_index, top_n=5):\n",
    "    if pub_index not in G_pub:\n",
    "        return []\n",
    "\n",
    "    neighbors = G_pub[pub_index]\n",
    "    similar = sorted(neighbors.items(), key=lambda x: x[1][\"weight\"], reverse=True)\n",
    "\n",
    "    return similar[:top_n]\n",
    "\n",
    "pub_index = 22\n",
    "pub_title = G_pub.nodes[pub_index].get(\"title\", \"undefined\")\n",
    "pub_keywords = G_pub.nodes[pub_index].get(\"keywords\", [])\n",
    "\n",
    "print(f\"Публикация {pub_index}: {pub_title}\")\n",
    "print(f\"Ключевые слова публикации {pub_index}: {pub_keywords}\")\n",
    "\n",
    "similar_pubs = find_similar_publications(G_pub, pub_index, top_n=5)\n",
    "print(f\"\\nПохожие публикации для публикации {pub_index}:\")\n",
    "\n",
    "for neighbor, attr in similar_pubs:\n",
    "    title = G_pub.nodes[neighbor].get(\"title\", \"undefined\")\n",
    "    print(f\"Публикация {neighbor}: {title}, общих ключевых слов: {attr['weight']}\")"
   ],
   "id": "93760faf568d2883",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Публикация 22: The Relationship Between Reasoning and Performance in Large Language\n",
      "  Models -- o3 (mini) Thinks Harder, Not Longer\n",
      "Ключевые слова публикации 22: ['reasoning', 'models', 'o3mini', 'accuracy', 'longer']\n",
      "\n",
      "Похожие публикации для публикации 22:\n",
      "Публикация 169: Unveiling Reasoning Thresholds in Language Models: Scaling, Fine-Tuning,\n",
      "  and Interpretability through Attention Maps, общих ключевых слов: 2\n",
      "Публикация 174: Social Genome: Grounded Social Reasoning Abilities of Multimodal Models, общих ключевых слов: 2\n",
      "Публикация 2: Testing the limits of fine-tuning to improve reasoning in vision\n",
      "  language models, общих ключевых слов: 1\n",
      "Публикация 15: Predicting gene essentiality and drug response from perturbation screens\n",
      "  in preclinical cancer models with LEAP: Layered Ensemble of Autoencoders and\n",
      "  Predictors, общих ключевых слов: 1\n",
      "Публикация 19: Mantis: Lightweight Calibrated Foundation Model for User-Friendly Time\n",
      "  Series Classification, общих ключевых слов: 1\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "8. Интерпретация результатов анализа:\n",
    "- В графе ключевых слов 768 узлов и 2423 ребра, что указывает на достаточно богатую сеть взаимосвязанных терминов\n",
    "- Топовые узлы по центральностям (например, «models», «learning», «model», «data», «llms») свидетельствуют о том, что эти термины являются ядром обсуждения в выбранной тематике и связующим звеном между различными кластерами\n",
    "- Модулярность ~0.6689 говорит о том, что граф ключевых слов хорошо разделён на кластеры: внутри каждого кластера связи существенно плотнее, чем между кластерами. Это означает, что существует выраженная тематическая сегментация (например, один кластер может быть связан с методами обучения, другой – с обработкой данных)\n",
    "- 250 узлов и 2391 ребро в графе публикаций указывают на то, что публикации тесно связаны через общие ключевые слова, что подтверждает высокую степень тематической взаимосвязи в выбранной области"
   ],
   "id": "aede4d432e7cbc94"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
